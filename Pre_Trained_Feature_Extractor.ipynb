{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMtz61Y4fjYQnN/k08lGKpU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parv-Agarwal/Internship-project/blob/main/Pre_Trained_Feature_Extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LZp6rxY3JIrj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "U9klIMRXWApR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Resize to accommodate the convolutions\n",
        "    transforms.Grayscale(num_output_channels=3),  # Convert to 3 channels\n",
        "    transforms.ToTensor()\n",
        "])\n"
      ],
      "metadata": {
        "id": "b7MHsxaMJL9F"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ik4lB2J6JMvb",
        "outputId": "5d41c322-fdf6-4745-a0e0-6ecfe8b67207"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:04<00:00, 1.99MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 487kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.51MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.27MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "8IEngUpZJPiT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature extractor class\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 5),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(32, 48, 5),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.conv_to_single_channel = nn.Conv2d(48, 1, kernel_size=1)  # Reduce channels to 1\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((28, 28))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)                        # Shape: (batch_size, 48, H, W)\n",
        "        x = self.conv_to_single_channel(x)      # Shape: (batch_size, 1, H, W)\n",
        "        x = self.adaptive_pool(x)               # Shape: (batch_size, 1, 28, 28)\n",
        "        x = x.view(x.size(0), -1)               # Flatten -> Shape: (batch_size, 28 * 28)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "T78Hk8_-JSZr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifier class\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(64, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "6sCs93UdJgFU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = FeatureExtractor().to(device)\n",
        "classifier = Classifier().to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(list(feature_extractor.parameters()) + list(classifier.parameters()), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "total_step = len(train_loader)"
      ],
      "metadata": {
        "id": "oHaOfQtoJnZk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    feature_extractor.train()\n",
        "    classifier.train()\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        features = feature_extractor(images)\n",
        "        outputs = classifier(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "# Save the feature extractor weights\n",
        "torch.save(feature_extractor.state_dict(), 'pre_trained_feature_extractor_weights.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPOGk_rKJuS0",
        "outputId": "f529cf68-e340-4e7e-c271-2174c88445df"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/938], Loss: 0.3368\n",
            "Epoch [1/10], Step [200/938], Loss: 0.2967\n",
            "Epoch [1/10], Step [300/938], Loss: 0.0489\n",
            "Epoch [1/10], Step [400/938], Loss: 0.0949\n",
            "Epoch [1/10], Step [500/938], Loss: 0.1043\n",
            "Epoch [1/10], Step [600/938], Loss: 0.1573\n",
            "Epoch [1/10], Step [700/938], Loss: 0.0907\n",
            "Epoch [1/10], Step [800/938], Loss: 0.1074\n",
            "Epoch [1/10], Step [900/938], Loss: 0.0277\n",
            "Epoch [2/10], Step [100/938], Loss: 0.1325\n",
            "Epoch [2/10], Step [200/938], Loss: 0.0464\n",
            "Epoch [2/10], Step [300/938], Loss: 0.1763\n",
            "Epoch [2/10], Step [400/938], Loss: 0.1241\n",
            "Epoch [2/10], Step [500/938], Loss: 0.2299\n",
            "Epoch [2/10], Step [600/938], Loss: 0.0841\n",
            "Epoch [2/10], Step [700/938], Loss: 0.0507\n",
            "Epoch [2/10], Step [800/938], Loss: 0.0178\n",
            "Epoch [2/10], Step [900/938], Loss: 0.0708\n",
            "Epoch [3/10], Step [100/938], Loss: 0.0634\n",
            "Epoch [3/10], Step [200/938], Loss: 0.0985\n",
            "Epoch [3/10], Step [300/938], Loss: 0.1077\n",
            "Epoch [3/10], Step [400/938], Loss: 0.0387\n",
            "Epoch [3/10], Step [500/938], Loss: 0.0916\n",
            "Epoch [3/10], Step [600/938], Loss: 0.0174\n",
            "Epoch [3/10], Step [700/938], Loss: 0.0958\n",
            "Epoch [3/10], Step [800/938], Loss: 0.1114\n",
            "Epoch [3/10], Step [900/938], Loss: 0.0432\n",
            "Epoch [4/10], Step [100/938], Loss: 0.0600\n",
            "Epoch [4/10], Step [200/938], Loss: 0.0418\n",
            "Epoch [4/10], Step [300/938], Loss: 0.0752\n",
            "Epoch [4/10], Step [400/938], Loss: 0.0100\n",
            "Epoch [4/10], Step [500/938], Loss: 0.0064\n",
            "Epoch [4/10], Step [600/938], Loss: 0.0521\n",
            "Epoch [4/10], Step [700/938], Loss: 0.0576\n",
            "Epoch [4/10], Step [800/938], Loss: 0.0226\n",
            "Epoch [4/10], Step [900/938], Loss: 0.0478\n",
            "Epoch [5/10], Step [100/938], Loss: 0.1181\n",
            "Epoch [5/10], Step [200/938], Loss: 0.0825\n",
            "Epoch [5/10], Step [300/938], Loss: 0.0143\n",
            "Epoch [5/10], Step [400/938], Loss: 0.0061\n",
            "Epoch [5/10], Step [500/938], Loss: 0.0560\n",
            "Epoch [5/10], Step [600/938], Loss: 0.0403\n",
            "Epoch [5/10], Step [700/938], Loss: 0.0098\n",
            "Epoch [5/10], Step [800/938], Loss: 0.1147\n",
            "Epoch [5/10], Step [900/938], Loss: 0.0169\n",
            "Epoch [6/10], Step [100/938], Loss: 0.1475\n",
            "Epoch [6/10], Step [200/938], Loss: 0.0045\n",
            "Epoch [6/10], Step [300/938], Loss: 0.0148\n",
            "Epoch [6/10], Step [400/938], Loss: 0.0257\n",
            "Epoch [6/10], Step [500/938], Loss: 0.0886\n",
            "Epoch [6/10], Step [600/938], Loss: 0.0900\n",
            "Epoch [6/10], Step [700/938], Loss: 0.0731\n",
            "Epoch [6/10], Step [800/938], Loss: 0.0341\n",
            "Epoch [6/10], Step [900/938], Loss: 0.0514\n",
            "Epoch [7/10], Step [100/938], Loss: 0.0925\n",
            "Epoch [7/10], Step [200/938], Loss: 0.0818\n",
            "Epoch [7/10], Step [300/938], Loss: 0.0178\n",
            "Epoch [7/10], Step [400/938], Loss: 0.0441\n",
            "Epoch [7/10], Step [500/938], Loss: 0.0397\n",
            "Epoch [7/10], Step [600/938], Loss: 0.0192\n",
            "Epoch [7/10], Step [700/938], Loss: 0.0005\n",
            "Epoch [7/10], Step [800/938], Loss: 0.0060\n",
            "Epoch [7/10], Step [900/938], Loss: 0.0490\n",
            "Epoch [8/10], Step [100/938], Loss: 0.0295\n",
            "Epoch [8/10], Step [200/938], Loss: 0.0070\n",
            "Epoch [8/10], Step [300/938], Loss: 0.0027\n",
            "Epoch [8/10], Step [400/938], Loss: 0.0009\n",
            "Epoch [8/10], Step [500/938], Loss: 0.0867\n",
            "Epoch [8/10], Step [600/938], Loss: 0.0054\n",
            "Epoch [8/10], Step [700/938], Loss: 0.0036\n",
            "Epoch [8/10], Step [800/938], Loss: 0.2634\n",
            "Epoch [8/10], Step [900/938], Loss: 0.0128\n",
            "Epoch [9/10], Step [100/938], Loss: 0.0373\n",
            "Epoch [9/10], Step [200/938], Loss: 0.0121\n",
            "Epoch [9/10], Step [300/938], Loss: 0.0120\n",
            "Epoch [9/10], Step [400/938], Loss: 0.0468\n",
            "Epoch [9/10], Step [500/938], Loss: 0.0084\n",
            "Epoch [9/10], Step [600/938], Loss: 0.0010\n",
            "Epoch [9/10], Step [700/938], Loss: 0.0112\n",
            "Epoch [9/10], Step [800/938], Loss: 0.0415\n",
            "Epoch [9/10], Step [900/938], Loss: 0.0132\n",
            "Epoch [10/10], Step [100/938], Loss: 0.0294\n",
            "Epoch [10/10], Step [200/938], Loss: 0.0404\n",
            "Epoch [10/10], Step [300/938], Loss: 0.0036\n",
            "Epoch [10/10], Step [400/938], Loss: 0.0467\n",
            "Epoch [10/10], Step [500/938], Loss: 0.0451\n",
            "Epoch [10/10], Step [600/938], Loss: 0.0098\n",
            "Epoch [10/10], Step [700/938], Loss: 0.0142\n",
            "Epoch [10/10], Step [800/938], Loss: 0.0036\n",
            "Epoch [10/10], Step [900/938], Loss: 0.0052\n"
          ]
        }
      ]
    }
  ]
}