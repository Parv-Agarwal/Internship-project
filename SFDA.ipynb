{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOXI5y650L3YmQgazq+KuXh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parv-Agarwal/Internship-project/blob/main/SFDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfOx6356wEiN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset_mnist.py\n",
        "\n",
        "# import torch\n",
        "# from torch.utils.data import Dataset\n",
        "# from torchvision import datasets, transforms\n",
        "# import os\n",
        "\n",
        "# class MNISTDataset(Dataset):\n",
        "#     def __init__(self, file_name, max_load=None, transform=None):\n",
        "#         # Load the dataset from the given file\n",
        "#         # Assuming the dataset is in a serialized format (e.g., .pt or .pth file)\n",
        "#         # For this example, we'll use torchvision's MNIST dataset\n",
        "#         self.transform = transform\n",
        "#         self.data = []\n",
        "#         self.labels = []\n",
        "\n",
        "#         # Load data\n",
        "#         if 'train' in file_name:\n",
        "#             dataset = datasets.MNIST(root='./data', train=True, download=True)\n",
        "#         else:\n",
        "#             dataset = datasets.MNIST(root='./data', train=False, download=True)\n",
        "\n",
        "#         self.data = dataset.data\n",
        "#         self.labels = dataset.targets\n",
        "\n",
        "#         # Limit the number of examples if max_load is specified\n",
        "#         if max_load is not None and max_load > 0 and max_load < len(self.data):\n",
        "#             self.data = self.data[:max_load]\n",
        "#             self.labels = self.labels[:max_load]\n",
        "#             print(f'<mnist> loading only {max_load} examples')\n",
        "\n",
        "#         print('<mnist> done')\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.labels)\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         img = self.data[index]\n",
        "#         label = self.labels[index]\n",
        "\n",
        "#         if len(img.shape) == 1:\n",
        "#             img = img.view(28, 28)\n",
        "\n",
        "#         if self.transform:\n",
        "#             img = self.transform(img)\n",
        "#         else:\n",
        "#             img = img.float()\n",
        "\n",
        "#         # Convert label to one-hot encoding\n",
        "#         label_one_hot = torch.zeros(10)\n",
        "#         label_one_hot[label] = 1.0\n",
        "\n",
        "#         return img, label_one_hot\n",
        "\n"
      ],
      "metadata": {
        "id": "biyNRVzcxf_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from PIL import Image\n",
        "\n",
        "class MNISTDataset(Dataset):\n",
        "    def __init__(self, file_name, max_load=None, transform=None):\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Load data\n",
        "        if 'train' in file_name:\n",
        "            dataset = datasets.MNIST(root='./data', train=True, download=True)\n",
        "        else:\n",
        "            dataset = datasets.MNIST(root='./data', train=False, download=True)\n",
        "\n",
        "        self.data = dataset.data\n",
        "        self.labels = dataset.targets\n",
        "\n",
        "        # Limit the number of examples if max_load is specified\n",
        "        if max_load is not None and max_load > 0 and max_load < len(self.data):\n",
        "            self.data = self.data[:max_load]\n",
        "            self.labels = self.labels[:max_load]\n",
        "            print(f'<mnist> loading only {max_load} examples')\n",
        "\n",
        "        print('<mnist> done')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    # def __getitem__(self, index):\n",
        "    #     img = self.data[index].numpy()  # Convert to numpy array\n",
        "    #     label = self.labels[index]\n",
        "\n",
        "    #     # Convert the numpy array to a PIL image\n",
        "    #     img = Image.fromarray(img, mode='L')\n",
        "\n",
        "    #     if self.transform:\n",
        "    #         img = self.transform(img)  # Apply transformations\n",
        "\n",
        "    #     # Convert label to one-hot encoding\n",
        "    #     label_one_hot = torch.zeros(10)\n",
        "    #     label_one_hot[label] = 1.0\n",
        "\n",
        "    #     return img, label_one_hot\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = self.data[index]  # Original image tensor\n",
        "        label = self.labels[index]\n",
        "\n",
        "        # Ensure the image tensor has exactly 2 dimensions (28, 28)\n",
        "        if img.ndim == 3 and img.shape[0] == 1:\n",
        "            img = img.squeeze(0)  # Remove the channel dimension if it's (1, 28, 28)\n",
        "\n",
        "        # Convert the tensor to a PIL Image\n",
        "        img = Image.fromarray(img.numpy(), mode='L')  # Convert to PIL image with mode 'L' for grayscale\n",
        "\n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        # Convert label to one-hot encoding\n",
        "        label_one_hot = torch.zeros(10)\n",
        "        label_one_hot[label] = 1.0\n",
        "\n",
        "        return img, label_one_hot\n",
        "\n"
      ],
      "metadata": {
        "id": "H7r6fSIPAotO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # dataset_mnistM.py\n",
        "\n",
        "# import torch\n",
        "# from torch.utils.data import Dataset\n",
        "# import numpy as np\n",
        "# from PIL import Image\n",
        "# import os\n",
        "# from torchvision import transforms\n",
        "\n",
        "# class MNISTMDataset(Dataset):\n",
        "#     def __init__(self, file_name, max_load=None, transform=None):\n",
        "#         # Load the MNIST-M dataset from the given file\n",
        "#         # Assuming the dataset is stored in .npy files or a custom format\n",
        "#         self.transform = transform\n",
        "#         self.data = []\n",
        "#         self.labels = []\n",
        "\n",
        "#         # Load data from file_name\n",
        "#         # For this example, we'll assume data is stored in .pt files\n",
        "#         # Replace this with the actual data loading code\n",
        "#         if not os.path.isfile(file_name):\n",
        "#             raise FileNotFoundError(f\"File {file_name} not found.\")\n",
        "\n",
        "#         data_dict = torch.load(file_name)\n",
        "#         self.data = data_dict['data']\n",
        "#         self.labels = data_dict['labels']\n",
        "\n",
        "#         n_example = self.data.size(0)\n",
        "#         print(f'nExample {n_example}')\n",
        "\n",
        "#         # Limit the number of examples if max_load is specified\n",
        "#         if max_load is not None and max_load > 0 and max_load < n_example:\n",
        "#             n_example = max_load\n",
        "#             print(f'<mnistM> loading only {n_example} examples')\n",
        "#             self.data = self.data[:n_example]\n",
        "#             self.labels = self.labels[:n_example]\n",
        "\n",
        "#         print('<mnistM> done')\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.labels)\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         img = self.data[index]\n",
        "#         label = self.labels[index]\n",
        "\n",
        "#         if isinstance(img, np.ndarray):\n",
        "#             img = Image.fromarray(img)\n",
        "#         elif torch.is_tensor(img):\n",
        "#             img = transforms.ToPILImage()(img)\n",
        "\n",
        "#         if self.transform:\n",
        "#             img = self.transform(img)\n",
        "#         else:\n",
        "#             img = transforms.ToTensor()(img)\n",
        "\n",
        "#         # Convert label to one-hot encoding\n",
        "#         label_one_hot = torch.zeros(10)\n",
        "#         label_one_hot[label] = 1.0\n",
        "\n",
        "#         return img, label_one_hot\n"
      ],
      "metadata": {
        "id": "F1NKXkHpx9Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTMDataset(Dataset):\n",
        "    def __init__(self, file_name, max_load=None, transform=None):\n",
        "        # Load the MNIST-M dataset from the given file\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "\n",
        "        if not os.path.isfile(file_name):\n",
        "            raise FileNotFoundError(f\"File {file_name} not found.\")\n",
        "\n",
        "        data_dict = torch.load(file_name)\n",
        "\n",
        "        # Access data and labels from the loaded tuple\n",
        "        self.data = data_dict[0]\n",
        "        self.labels = data_dict[1]\n",
        "\n",
        "        n_example = self.data.size(0)\n",
        "        print(f'nExample {n_example}')\n",
        "\n",
        "        if max_load is not None and max_load > 0 and max_load < n_example:\n",
        "            n_example = max_load\n",
        "            print(f'<mnistM> loading only {n_example} examples')\n",
        "            self.data = self.data[:n_example]\n",
        "            self.labels = self.labels[:n_example]\n",
        "\n",
        "        print('<mnistM> done')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    # def __getitem__(self, index):\n",
        "    #     img = self.data[index]\n",
        "    #     label = self.labels[index]\n",
        "\n",
        "    #     if isinstance(img, np.ndarray):\n",
        "    #         img = Image.fromarray(img)\n",
        "    #     elif torch.is_tensor(img):\n",
        "    #         img = transforms.ToPILImage()(img)\n",
        "\n",
        "    #     if self.transform:\n",
        "    #         img = self.transform(img)\n",
        "    #     else:\n",
        "    #         img = transforms.ToTensor()(img)\n",
        "\n",
        "    #     # Convert label to one-hot encoding\n",
        "    #     label_one_hot = torch.zeros(10)\n",
        "    #     label_one_hot[label] = 1.0\n",
        "\n",
        "    #     return img, label_one_hot\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = self.data[index]  # Original image tensor\n",
        "        label = self.labels[index]\n",
        "\n",
        "        # Ensure the image tensor has 3 dimensions (1, H, W) for grayscale images\n",
        "        if img.ndim == 2:  # If img is (H, W), convert it to (1, H, W)\n",
        "            img = img.unsqueeze(0)\n",
        "\n",
        "        # Convert to 3-channel RGB by repeating the single channel\n",
        "        img = img.repeat(3, 1, 1)  # Convert to (3, 28, 28) for RGB-like tensor\n",
        "\n",
        "        # Convert the tensor to numpy and ensure it is of type uint8\n",
        "        img = img.numpy().astype(np.uint8)\n",
        "\n",
        "        # Convert to a PIL image\n",
        "        img = Image.fromarray(img.transpose(1, 2, 0), mode='RGB')  # Convert to RGB PIL image\n",
        "\n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        # Convert label to one-hot encoding\n",
        "        label_one_hot = torch.zeros(10)\n",
        "        label_one_hot[label] = 1.0\n",
        "\n",
        "        return img, label_one_hot\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YN4ZB39DjI_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogSumExp(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LogSumExp, self).__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        max_val, _ = torch.max(input, dim=1, keepdim=True)\n",
        "        output = input - max_val\n",
        "        output = max_val + torch.log(torch.sum(torch.exp(output), dim=1, keepdim=True))\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "4a_zbndG2WVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = {\n",
        "    'dataset': 'mnist',\n",
        "    'batchSize': 64,\n",
        "    'loadSize': 33,\n",
        "    'fineSize': 32,\n",
        "    'nz': 100,               # # of dim for Z\n",
        "    'ngf': 64,               # # of gen filters in first conv layer\n",
        "    'ndf': 64,               # # of discrim filters in first conv layer\n",
        "    'nThreads': 4,           # # of data loading threads to use\n",
        "    'niter': 10000,          # # of iter at starting learning rate\n",
        "    'lr': 0.0002,            # initial learning rate for adam\n",
        "    'beta1': 0.5,            # momentum term of adam\n",
        "    'ntrain': float('inf'),  # # of examples per epoch\n",
        "    'display': 0,            # display samples while training\n",
        "    'display_id': 0,         # display window id\n",
        "    'gpu': 1,                # gpu = 0 is CPU mode. gpu=X is GPU mode on GPU X\n",
        "    'name': 'Logfiles',\n",
        "    'noise': 'normal',       # 'uniform' or 'normal'\n",
        "    'epoch_save_modulo': 1,\n",
        "    'manual_seed': 4,        # Seed\n",
        "    'nc': 3,                 # # of channels in input\n",
        "    'save': 'logs/',         # Directory to save logs\n",
        "    'data_root': './data',   # Root directory for datasets\n",
        "    'lamda': 1,              # Lambda value for GRL\n",
        "    'baseLearningRate': 0.0002,\n",
        "    'max_epoch': 10000,\n",
        "    'gamma': 0.001,\n",
        "    'power': 0.75,\n",
        "    'max_epoch_grl': 10000,\n",
        "    'alpha': 10,\n",
        "}\n",
        "\n",
        "train_gen_epoch = 25"
      ],
      "metadata": {
        "id": "u0-KvzP4yNFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "import random\n",
        "random.seed(opt['manual_seed'])\n",
        "torch.manual_seed(opt['manual_seed'])\n",
        "torch.set_num_threads(1)\n",
        "\n",
        "if torch.cuda.is_available() and opt['gpu'] > 0:\n",
        "    torch.cuda.manual_seed_all(opt['manual_seed'])\n",
        "    device = torch.device(f'cuda:{opt[\"gpu\"] - 1}')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(f\"Random Seed: {opt['manual_seed']}\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Initialize data loaders\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(opt['fineSize']),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRyTQzy4y1x2",
        "outputId": "ca066ecd-53f1-467f-de0d-b9d90631c6d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed: 4\n",
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train_path = 'mnist_train.pt'  # Adjust the path as needed\n",
        "mnist_test_path = 'mnist_test.pt'    # Adjust the path as needed\n",
        "max_train_load = None  # Set to None or an integer value\n",
        "max_test_load = None   # Set to None or an integer value\n",
        "\n",
        "mnist_train_dataset = MNISTDataset(mnist_train_path, max_load=max_train_load, transform=transform)\n",
        "mnist_test_dataset = MNISTDataset(mnist_test_path, max_load=max_test_load, transform=transform)\n",
        "\n",
        "mnist_train_loader = DataLoader(mnist_train_dataset, batch_size=opt['batchSize'], shuffle=True, num_workers=opt['nThreads'])\n",
        "mnist_test_loader = DataLoader(mnist_test_dataset, batch_size=opt['batchSize'], shuffle=False, num_workers=opt['nThreads'])\n",
        "\n",
        "print(f\"MNIST Dataset: Size: {len(mnist_train_dataset)}\")\n",
        "\n",
        "# Load MNIST-M dataset\n",
        "mnistm_train_path = 'mnist_m_train.pt'  # Adjust the path as needed\n",
        "mnistm_test_path = 'mnist_m_test.pt'    # Adjust the path as needed\n",
        "Num_Train_Target = 59001\n",
        "Num_Test_Target = 10001\n",
        "\n",
        "mnistm_train_dataset = MNISTMDataset(mnistm_train_path, max_load=Num_Train_Target, transform=transform)\n",
        "mnistm_test_dataset = MNISTMDataset(mnistm_test_path, max_load=Num_Test_Target, transform=transform)\n",
        "\n",
        "mnistm_train_loader = DataLoader(mnistm_train_dataset, batch_size=opt['batchSize'], shuffle=True, num_workers=opt['nThreads'])\n",
        "mnistm_test_loader = DataLoader(mnistm_test_dataset, batch_size=opt['batchSize'], shuffle=False, num_workers=opt['nThreads'])\n",
        "\n",
        "print(f\"MNIST-M Dataset: Size: {len(mnistm_train_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVoeyuWZzqjP",
        "outputId": "3935f1d0-1dd9-4f6a-f3ba-445db2dab459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<mnist> done\n",
            "<mnist> done\n",
            "MNIST Dataset: Size: 60000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-77-cafaab4cf4b2>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data_dict = torch.load(file_name)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nExample 60000\n",
            "<mnistM> loading only 59001 examples\n",
            "<mnistM> done\n",
            "nExample 10000\n",
            "<mnistM> done\n",
            "MNIST-M Dataset: Size: 59001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1 or classname.find('Linear') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias.data, 0)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "metadata": {
        "id": "2_94LGPZ0O0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz, ngf, nc):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # Input is Z + one-hot class vector\n",
        "            nn.ConvTranspose2d(nz + 10, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # State size: (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # State size: (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # State size: (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf * 2, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # Output size: (nc) x 32 x 32\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "metadata": {
        "id": "OXwP7XO00ViN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class Discriminator(nn.Module):\n",
        "#     def __init__(self, nc, ndf):\n",
        "#         super(Discriminator, self).__init__()\n",
        "#         self.main = nn.Sequential(\n",
        "#             # Input is (nc) x 32 x 32\n",
        "#             nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),  # (ndf) x 16 x 16\n",
        "#             nn.LeakyReLU(0.2, inplace=True),\n",
        "#             nn.Conv2d(ndf, ndf * 4, 4, 2, 1, bias=False),  # (ndf*4) x 8 x 8\n",
        "#             nn.BatchNorm2d(ndf * 4),\n",
        "#             nn.LeakyReLU(0.2, inplace=True),\n",
        "#             nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),  # (ndf*8) x 4 x 4\n",
        "#             nn.BatchNorm2d(ndf * 8),\n",
        "#             nn.LeakyReLU(0.2, inplace=True),\n",
        "#             nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),  # Output is single value\n",
        "#             nn.Sigmoid()\n",
        "#         )\n",
        "\n",
        "#     def forward(self, input):\n",
        "#         return self.main(input).view(-1, 1)"
      ],
      "metadata": {
        "id": "wn_yjEfW0ZF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, nc, ndf):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(1, ndf, 4, 2, 1, bias=False),  # Changed from 3 to 1 for grayscale input\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input).view(-1, 1)"
      ],
      "metadata": {
        "id": "gUOI3odcDsgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Function\n",
        "class GradientReversalFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, lambda_):\n",
        "        ctx.lambda_ = lambda_\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return grad_output.neg() * ctx.lambda_, None\n",
        "\n",
        "def grad_reverse(x, lambda_=1.0):\n",
        "    return GradientReversalFunction.apply(x, lambda_)"
      ],
      "metadata": {
        "id": "_e9P2l1L0fb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class FeatureExtractor(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(FeatureExtractor, self).__init__()\n",
        "#         self.conv = nn.Sequential(\n",
        "#             nn.Conv2d(3, 32, 5),  # Input channels, output channels, kernel size\n",
        "#             nn.ReLU(True),\n",
        "#             nn.MaxPool2d(2, 2),\n",
        "#             nn.Conv2d(32, 48, 5),\n",
        "#             nn.ReLU(True),\n",
        "#             nn.MaxPool2d(2, 2)\n",
        "#         )\n",
        "#         self.fc_features = 48 * 5 * 5  # Calculate the output size\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.conv(x)\n",
        "#         x = x.view(-1, self.fc_features)\n",
        "#         return x\n"
      ],
      "metadata": {
        "id": "ic1UnXRD0zZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 5),  # Changed from 3 to 1 for grayscale input\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(32, 48, 5),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.fc_features = 48 * 5 * 5\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(-1, self.fc_features)\n",
        "        return x"
      ],
      "metadata": {
        "id": "KNIC5INsENjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ClassClassifier, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(48 * 5 * 5, 100),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(100, 100),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(100, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "mfc2NkUD1Bn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DomainClassifier(nn.Module):\n",
        "    def __init__(self, lambda_=1.0):\n",
        "        super(DomainClassifier, self).__init__()\n",
        "        self.lambda_ = lambda_\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(48 * 5 * 5, 100),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(100, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = grad_reverse(x, self.lambda_)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "zYjEREoU1FE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netG = Generator(opt['nz'], opt['ngf'], opt['nc']).to(device)\n",
        "netD = Discriminator(opt['nc'], opt['ndf']).to(device)\n",
        "feature_extractor = FeatureExtractor().to(device)\n",
        "class_classifier = ClassClassifier().to(device)\n",
        "domain_classifier = DomainClassifier(lambda_=opt['lamda']).to(device)\n",
        "\n",
        "netG.apply(weights_init)\n",
        "netD.apply(weights_init)\n",
        "feature_extractor.apply(weights_init)\n",
        "class_classifier.apply(weights_init)\n",
        "domain_classifier.apply(weights_init)\n",
        "\n",
        "# Loss functions\n",
        "adversarial_loss = nn.BCELoss().to(device)\n",
        "classification_loss = nn.NLLLoss().to(device)\n",
        "cross_entropy_loss = nn.CrossEntropyLoss().to(device)\n",
        "log_sum_exp = LogSumExp().to(device)\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = optim.Adam(netG.parameters(), lr=opt['lr'], betas=(opt['beta1'], 0.999))\n",
        "optimizer_D = optim.Adam(netD.parameters(), lr=opt['lr'], betas=(opt['beta1'], 0.999))\n",
        "optimizer_feature = optim.SGD(feature_extractor.parameters(), lr=opt['baseLearningRate'], momentum=0.9)\n",
        "optimizer_class = optim.SGD(class_classifier.parameters(), lr=opt['baseLearningRate'], momentum=0.9)\n",
        "optimizer_domain = optim.SGD(domain_classifier.parameters(), lr=opt['baseLearningRate'], momentum=0.9)"
      ],
      "metadata": {
        "id": "WWJHLYWa1GlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    netG.train()\n",
        "    netD.train()\n",
        "    feature_extractor.train()\n",
        "    class_classifier.train()\n",
        "    domain_classifier.train()\n",
        "\n",
        "    avg_loss = 0\n",
        "    avg_acc = 0\n",
        "    count = 0\n",
        "\n",
        "    data_iter = iter(mnistm_train_loader)\n",
        "    len_dataloader = min(len(mnist_train_loader), len(mnistm_train_loader))\n",
        "\n",
        "    for batch_idx in range(len_dataloader):\n",
        "        # Get source data (MNIST)\n",
        "        try:\n",
        "            source_data, source_labels_one_hot = next(iter(mnist_train_loader))\n",
        "        except StopIteration:\n",
        "            data_iter = iter(mnist_train_loader)\n",
        "            source_data, source_labels_one_hot = next(data_iter)\n",
        "\n",
        "        # Get target data (MNIST-M)\n",
        "        try:\n",
        "            target_data, _ = next(iter(mnistm_train_loader))\n",
        "        except StopIteration:\n",
        "            data_iter = iter(mnistm_train_loader)\n",
        "            target_data, _ = next(data_iter)\n",
        "\n",
        "        if source_data.size(0) != opt['batchSize'] or target_data.size(0) != opt['batchSize']:\n",
        "            continue  # Skip incomplete batch\n",
        "\n",
        "        # Move data to device\n",
        "        source_data = source_data.to(device)\n",
        "        source_labels = torch.argmax(source_labels_one_hot, dim=1).to(device)\n",
        "        target_data = target_data.to(device)\n",
        "\n",
        "        batch_size = source_data.size(0)\n",
        "        label_real = torch.full((batch_size, 1), 1.0, device=device)\n",
        "        label_fake = torch.full((batch_size, 1), 0.0, device=device)\n",
        "\n",
        "        # Generate fake images\n",
        "        noise = torch.randn(batch_size, opt['nz'], 1, 1, device=device)\n",
        "        class_labels = torch.randint(0, 10, (batch_size,), device=device)\n",
        "        one_hot_labels = torch.zeros(batch_size, 10, 1, 1, device=device)\n",
        "        one_hot_labels.scatter_(1, class_labels.view(batch_size, 1, 1, 1), 1)\n",
        "        noise_with_labels = torch.cat((noise, one_hot_labels), 1)\n",
        "\n",
        "        fake_images = netG(noise_with_labels)\n",
        "\n",
        "        # Train Discriminator\n",
        "        netD.zero_grad()\n",
        "        # Discriminator loss on real data\n",
        "        output_real = netD(source_data)\n",
        "        errD_real = adversarial_loss(output_real, label_real)\n",
        "        # Discriminator loss on fake data\n",
        "        output_fake = netD(fake_images.detach())\n",
        "        errD_fake = adversarial_loss(output_fake, label_fake)\n",
        "        # Total discriminator loss\n",
        "        errD = errD_real + errD_fake\n",
        "        errD.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Train Generator\n",
        "        netG.zero_grad()\n",
        "        output_fake = netD(fake_images)\n",
        "        errG = adversarial_loss(output_fake, label_real)\n",
        "        errG.backward(retain_graph=True)\n",
        "\n",
        "        # Compute classification loss\n",
        "        features = feature_extractor(fake_images)\n",
        "        class_outputs = class_classifier(features)\n",
        "        class_loss = cross_entropy_loss(class_outputs, class_labels)\n",
        "        class_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # Update feature extractor and classifiers\n",
        "        feature_extractor.zero_grad()\n",
        "        class_classifier.zero_grad()\n",
        "        domain_classifier.zero_grad()\n",
        "\n",
        "        # Prepare domain labels\n",
        "        source_domain_labels = torch.zeros(batch_size, dtype=torch.long, device=device)\n",
        "        target_domain_labels = torch.ones(batch_size, dtype=torch.long, device=device)\n",
        "\n",
        "        # Forward pass for domain classification\n",
        "        features_source = feature_extractor(fake_images.detach())\n",
        "        features_target = feature_extractor(target_data)\n",
        "        domain_output_source = domain_classifier(features_source)\n",
        "        domain_output_target = domain_classifier(features_target)\n",
        "        domain_output = torch.cat((domain_output_source, domain_output_target), 0)\n",
        "        domain_labels = torch.cat((source_domain_labels, target_domain_labels), 0)\n",
        "\n",
        "        domain_loss = cross_entropy_loss(domain_output, domain_labels)\n",
        "        domain_loss.backward()\n",
        "        optimizer_feature.step()\n",
        "        optimizer_class.step()\n",
        "        optimizer_domain.step()\n",
        "\n",
        "        # Update average loss and accuracy\n",
        "        avg_loss += errG.item()\n",
        "        _, predicted = torch.max(class_outputs.data, 1)\n",
        "        correct = (predicted == class_labels).sum().item()\n",
        "        avg_acc += correct / batch_size\n",
        "        count += 1\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Epoch [{epoch}/{opt[\"niter\"]}] Batch [{batch_idx}/{len_dataloader}] '\n",
        "                  f'Loss D: {errD.item():.4f}, Loss G: {errG.item():.4f}, '\n",
        "                  f'Class Loss: {class_loss.item():.4f}, Domain Loss: {domain_loss.item():.4f}')\n",
        "\n",
        "    avg_loss /= count\n",
        "    avg_acc /= count\n",
        "    return avg_acc, avg_loss"
      ],
      "metadata": {
        "id": "oXedOFMY2a_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(epoch):\n",
        "    netG.eval()\n",
        "    feature_extractor.eval()\n",
        "    class_classifier.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, labels_one_hot) in enumerate(mnistm_test_loader):\n",
        "            if data.size(0) != opt['batchSize']:\n",
        "                continue  # Skip incomplete batch\n",
        "\n",
        "            data = data.to(device)\n",
        "            labels = torch.argmax(labels_one_hot, dim=1).to(device)\n",
        "            features = feature_extractor(data)\n",
        "            outputs = class_classifier(features)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "OH1ZipoK2kmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, opt['niter'] + 1):\n",
        "    train_acc, train_loss = train(epoch)\n",
        "    if epoch > train_gen_epoch:\n",
        "        test_acc = test(epoch)\n",
        "        # Save model checkpoints if needed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kTy5Oys32n6I",
        "outputId": "bd182ea5-9a86-48ca-dac2-dc1251b14fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [64, 1, 4, 4], expected input[64, 3, 32, 32] to have 1 channels, but got 3 channels instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-c91ff3d6a57c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'niter'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtrain_gen_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# Save model checkpoints if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-92-46a57ccada48>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0merrD_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversarial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Discriminator loss on fake data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0moutput_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0merrD_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversarial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# Total discriminator loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-85-8af5c4f2d3d6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 454\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    455\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 1, 4, 4], expected input[64, 3, 32, 32] to have 1 channels, but got 3 channels instead"
          ]
        }
      ]
    }
  ]
}